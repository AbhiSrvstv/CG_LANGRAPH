{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install -U langgraph langsmith"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pK78WuXaohJ8",
        "outputId": "a19546a1-5fa2-4505-f4a4-5dafa35f6c0c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.4.8)\n",
            "Requirement already satisfied: langsmith in /usr/local/lib/python3.11/dist-packages (0.3.45)\n",
            "Collecting langsmith\n",
            "  Using cached langsmith-0.4.1-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.65)\n",
            "Requirement already satisfied: langgraph-checkpoint>=2.0.26 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.1.0)\n",
            "Requirement already satisfied: langgraph-prebuilt>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.2.2)\n",
            "Requirement already satisfied: langgraph-sdk>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.70)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.7)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith) (3.10.18)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langsmith) (24.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith) (0.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.16.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (4.14.0)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint>=2.0.26->langgraph) (1.10.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith) (2.4.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TFEuFD0EoWGv"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph, START\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    # Messages have the type \"list\". The `add_messages` function\n",
        "    # in the annotation defines how this state key should be updated\n",
        "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "#AIzaSyCXp230h__4BovmnNDxBWwjIfbyZTCvUKA"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##azure ai\n"
      ],
      "metadata": {
        "id": "AykFOR0Hpwfk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "J8sV3KbLoWGy",
        "outputId": "d469f185-ffdc-4738-a294-79049c18b7a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain[openai] in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain[openai]) (0.3.65)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain[openai]) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain[openai]) (0.3.45)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain[openai]) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain[openai]) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain[openai]) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain[openai]) (6.0.2)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (from langchain[openai]) (0.3.24)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain[openai]) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain[openai]) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain[openai]) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain[openai]) (4.14.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain[openai]) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain[openai]) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain[openai]) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain[openai]) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain[openai]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain[openai]) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain[openai]) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain[openai]) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain[openai]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain[openai]) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain[openai]) (2025.6.15)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain[openai]) (3.2.3)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.86.0 in /usr/local/lib/python3.11/dist-packages (from langchain-openai->langchain[openai]) (1.86.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai->langchain[openai]) (0.9.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain[openai]) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain[openai]) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain[openai]) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain[openai]) (3.0.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai->langchain[openai]) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai->langchain[openai]) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai->langchain[openai]) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai->langchain[openai]) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai->langchain[openai]) (2024.11.6)\n"
          ]
        }
      ],
      "source": [
        "pip install -U \"langchain[openai]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gvAVaSmKoWG1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"1lOkjRo9bsDnbAE2v1qVagkmEj6mT111wak1spzwGQMDsqFoVT1aJQQJ99BDAC5RqLJXJ3w3AAABACOGNvwZ\"\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://agentic-accelerator-pod-openai-we.openai.azure.com/\"\n",
        "os.environ[\"OPENAI_API_VERSION\"] = \"2024-12-01-preview\"\n",
        "\n",
        "llm_azure = init_chat_model(\n",
        "    \"azure_openai:gpt-4o\",\n",
        "    azure_deployment=\"gpt-4o\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm_azure.invoke(state[\"messages\"])]}\n",
        "\n",
        "\n",
        "# The first argument is the unique node name\n",
        "# The second argument is the function or object that will be called whenever\n",
        "# the node is used.\n",
        "graph_builder.add_node(\"chatbot\", chatbot)"
      ],
      "metadata": {
        "id": "XaHhGqxWuqgq",
        "outputId": "036e9bec-e56f-41d2-bcd8-0a5d9e8ddcf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7d7851d54350>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder.add_edge(START, \"chatbot\")"
      ],
      "metadata": {
        "id": "2xbl_UTtuqJ3",
        "outputId": "4715e2f8-ff9b-4a10-c385-7f0b76364800",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7d7851d54350>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "WYYGErHbu09W"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass"
      ],
      "metadata": {
        "id": "CiFXVQddu6gb",
        "outputId": "7e47ba24-2496-4358-b519-173acf51f815",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def stream_graph_updates(user_input: str):\n",
        "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
        "        for value in event.values():\n",
        "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
        "\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        user_input = input(\"User: \")\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "        stream_graph_updates(user_input)\n",
        "    except:\n",
        "        # fallback if input() is not available\n",
        "        user_input = \"What do you know about LangGraph?\"\n",
        "        print(\"User: \" + user_input)\n",
        "        stream_graph_updates(user_input)\n",
        "        break"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-SGS6lBiu_sZ",
        "outputId": "428a648c-1fcc-4b92-e26b-862424fb8134",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: provide me the prompt for the x ray image analysis using multi agent and supervisor using langgraph\n",
            "Assistant: Certainly! Below is a structured prompt design that utilizes a multi-agent system with a supervisor layer in LangGraph for X-ray image analysis.\n",
            "\n",
            "---\n",
            "\n",
            "## **Prompt: X-ray Image Analysis Using Multi-agent Approach**\n",
            "\n",
            "### **Objective**\n",
            "Design a multi-agent system using LangGraph, where individual agents specialize in specific tasks such as feature extraction, anomaly detection, pattern recognition, and report summarization. A supervisor agent oversees the workflow and ensures collaboration among agents for accurate analysis of X-ray images.\n",
            "\n",
            "---\n",
            "\n",
            "### **Input**\n",
            "1. **X-ray Image:** Raw X-ray image provided in digital format (example `.jpg`, `.png`, `.dicom`).\n",
            "2. **Context:** Patient medical history and metadata (e.g., age, gender, symptoms, previous medical records, timestamp of X-ray image taken).\n",
            "3. **Specific Area of Focus:** Any specific region to investigate (e.g., lungs for pneumonia, bones for fractures).\n",
            "\n",
            "---\n",
            "\n",
            "### **Roles and Workflow**\n",
            "1. **Feature Extraction Agent (FEA):**\n",
            "   - Task: Analyze the X-ray image to extract visual features such as density changes, edge contours, organ structures, etc.\n",
            "   - Tools: Image processing libraries, pre-trained medical imaging models (e.g., PyTorch, TensorFlow-based).\n",
            "\n",
            "2. **Anomaly Detection Agent (ADA):**\n",
            "   - Task: Identify anomalies such as fractures, opacity, abnormal growth patterns, or irregular density in the X-ray image.\n",
            "   - Tools: Compare extracted features against a library of medical data or trained algorithms for anomaly classification.\n",
            "\n",
            "3. **Pattern Recognition Agent (PRA):**\n",
            "   - Task: Correlate visual features and anomalies with known diseases or pathological conditions. Create an intermediate diagnosis.\n",
            "   - Tools: Machine learning models trained on labeled X-ray datasets (e.g., Chest X-ray 14, MURA dataset).\n",
            "\n",
            "4. **Report Summarization Agent (RSA):**\n",
            "   - Task: Generate a concise report summarizing findings, including potential diagnoses and recommendations for further testing or treatment.\n",
            "   - Tools: Natural Language Generation models (GPT-based or custom-trained medical language models).\n",
            "\n",
            "5. **Supervisor Agent (SA):**\n",
            "   - Task: Coordinate the workflow between agents to ensure proper flow of information and resolve conflicts. Verify final outputs for consistency and medical relevance.\n",
            "   - Tools: Rule-based systems, decision-making algorithms, and human feedback mechanisms (if available).\n",
            "\n",
            "---\n",
            "\n",
            "### **Example Prompt for Each Agent**\n",
            "\n",
            "1. **Feature Extraction Agent (FEA):**\n",
            "   ```markdown\n",
            "   You are the Feature Extraction Agent specializing in analyzing X-ray images. Your task is to identify key visual features such as density patterns, edge contours, and regions of structural changes.\n",
            "   Input: Raw X-ray image\n",
            "   Output: Concise descriptions of detected features (e.g., \"Increased opacity in upper lobe of the right lung\").\n",
            "   ```\n",
            "\n",
            "2. **Anomaly Detection Agent (ADA):**\n",
            "   ```markdown\n",
            "   You are the Anomaly Detection Agent. You analyze features provided by the FEA to detect abnormalities like fractures, opacity, or irregular growths. You also rate the severity of each anomaly.\n",
            "   Input: Feature data extracted by FEA\n",
            "   Output: List of anomalies with detailed descriptions and severity ratings.\n",
            "   ```\n",
            "\n",
            "3. **Pattern Recognition Agent (PRA):**\n",
            "   ```markdown\n",
            "   You are the Pattern Recognition Agent. Your role is to use anomalies detected by ADA to infer possible pathological conditions based on medical knowledge and historical datasets.\n",
            "   Input: Anomalies and severity detected by ADA\n",
            "   Output: Potential diagnoses and associated probabilities.\n",
            "   ```\n",
            "\n",
            "4. **Report Summarization Agent (RSA):**\n",
            "   ```markdown\n",
            "   You are the Report Summarization Agent. Your role is to synthesize findings into a medically concise report suitable for physicians.\n",
            "   Input: Diagnoses from PRA and context data from metadata\n",
            "   Output: Final report suitable for doctors (including observations, diagnoses, and recommendations).\n",
            "   ```\n",
            "\n",
            "5. **Supervisor Agent (SA):**\n",
            "   ```markdown\n",
            "   You are the Supervisor Agent overseeing the multi-agent X-ray image analysis workflow. Ensure proper collaboration, verify outputs for consistency, and cross-check findings using contextual information.\n",
            "   Input: Outputs from FEA, ADA, PRA, and RSA, plus metadata\n",
            "   Output: Final verified workflow and authorized medical report.\n",
            "   ```\n",
            "\n",
            "---\n",
            "\n",
            "### **LangGraph Configuration**\n",
            "- Agents interconnected via LangGraph to form a hierarchical system of communication.\n",
            "- Workflow:\n",
            "  1. X-ray image and metadata fed into FEA â†’ Output passed to ADA.\n",
            "  2. ADA flags anomalies â†’ Data passed to PRA.\n",
            "  3. PRA infers diagnoses â†’ Findings sent to RSA.\n",
            "  4. RSA drafts report â†’ Report audited by SA.\n",
            "- Supervisor coordinates data flow and ensures final report quality.\n",
            "\n",
            "---\n",
            "\n",
            "### **Example Output**\n",
            "**Final Report:**\n",
            "```markdown\n",
            "Patient Information:\n",
            "- Age: 35 years\n",
            "- Gender: Male\n",
            "- Symptoms: Persistent cough, shortness of breath\n",
            "\n",
            "Findings:\n",
            "- Increased opacity in the upper lobe of the right lung.\n",
            "- No visible structural damage to rib cage or trachea.\n",
            "- Possible mild pleural effusion detected.\n",
            "\n",
            "Diagnoses:\n",
            "- High probability of pneumonia (87% confidence).\n",
            "- Low probability of lung cancer (12% confidence).\n",
            "\n",
            "Recommendations:\n",
            "- Immediate medical consultation for antibiotic treatment.\n",
            "- CT scan recommended for further investigation.\n",
            "\n",
            "End of Report.\n",
            "```\n",
            "\n",
            "---\n",
            "\n",
            "This prompt allows the multi-agent system to perform systematic analysis of X-ray images, leveraging the strengths of specialization and oversight provided by LangGraph. Use this as a template and tailor specific configurations based on your implementation needs.\n",
            "User: provide me the code with a supervisor and these agents on it for the x ray image analysis using langraph\n",
            "Assistant: Certainly! Below is an example code snippet demonstrating how you can leverage the **`LangGraph`**, a framework designed to create structured workflows with multiple agents and a supervising agent.\n",
            "\n",
            "In this example, we'll have a `SupervisorAgent` overseeing three specialized agents (`ImageProcessingAgent`, `DiagnosisAgent`, and `ReportGenerationAgent`) for analyzing X-ray images:\n",
            "\n",
            "---\n",
            "\n",
            "### Dependencies\n",
            "Ensure you have the following libraries installed:\n",
            "\n",
            "```bash\n",
            "pip install langchain pillow langgraph\n",
            "```\n",
            "\n",
            "---\n",
            "\n",
            "### Code: X-Ray Image Analysis with LangGraph\n",
            "\n",
            "```python\n",
            "from langgraph import LangGraph, Agent, Supervisor\n",
            "from PIL import Image\n",
            "\n",
            "# Sample agents for the X-Ray Workflow\n",
            "class ImageProcessingAgent(Agent):\n",
            "    def process(self, x_ray_image: Image.Image):\n",
            "        # Simulate feature extraction (e.g., bone structure detection)\n",
            "        features = {\"bone_density\": \"medium\", \"fracture\": \"none\", \"anomalies\": [\"shadow in lung\"]}\n",
            "        print(f\"ImageProcessingAgent: Extracted features {features}\")\n",
            "        return features\n",
            "\n",
            "class DiagnosisAgent(Agent):\n",
            "    def process(self, features: dict):\n",
            "        # Simulate diagnosis based on extracted features\n",
            "        diagnosis = \"Possible Pneumonia due to lung shadow. No fractures detected.\"\n",
            "        print(f\"DiagnosisAgent: Diagnosis result - {diagnosis}\")\n",
            "        return diagnosis\n",
            "\n",
            "class ReportGenerationAgent(Agent):\n",
            "    def process(self, diagnosis: str):\n",
            "        # Simulate report generation\n",
            "        report = f\"X-Ray Report:\\nDiagnosis: {diagnosis}\\nAction: Follow up with a physician for further tests.\"\n",
            "        print(f\"ReportGenerationAgent: Generated Report - \\n{report}\")\n",
            "        return report\n",
            "\n",
            "\n",
            "# Supervisor coordinating all agents\n",
            "class SupervisorAgent(Supervisor):\n",
            "    def supervise(self, x_ray_image: Image.Image):\n",
            "        print(\"SupervisorAgent: Starting X-Ray image analysis workflow...\\n\")\n",
            "        \n",
            "        # Step 1: Process the image\n",
            "        processing_agent = ImageProcessingAgent()\n",
            "        extracted_features = processing_agent.process(x_ray_image)\n",
            "        \n",
            "        # Step 2: Diagnosis from features\n",
            "        diagnosis_agent = DiagnosisAgent()\n",
            "        diagnosis = diagnosis_agent.process(extracted_features)\n",
            "        \n",
            "        # Step 3: Generate report\n",
            "        report_agent = ReportGenerationAgent()\n",
            "        final_report = report_agent.process(diagnosis)\n",
            "        \n",
            "        print(\"\\nSupervisorAgent: Workflow complete!\")\n",
            "        return final_report\n",
            "\n",
            "\n",
            "# Example run\n",
            "if __name__ == \"__main__\":\n",
            "    # Load a sample X-Ray image (replace with actual image path)\n",
            "    x_ray_image_path = \"sample_x_ray_image.png\"  # Replace with the actual image file path\n",
            "    try:\n",
            "        x_ray_image = Image.open(x_ray_image_path).convert(\"L\")  # Convert to grayscale for simplicity\n",
            "        supervisor = SupervisorAgent()\n",
            "        \n",
            "        # Start the workflow\n",
            "        xray_analysis_report = supervisor.supervise(x_ray_image)\n",
            "        \n",
            "        # Output the final report\n",
            "        print(\"\\nFinal Report:\\n\", xray_analysis_report)\n",
            "    except Exception as e:\n",
            "        print(f\"Error: {e}\")\n",
            "```\n",
            "\n",
            "---\n",
            "\n",
            "### How It Works\n",
            "1. **ImageProcessingAgent**:\n",
            "   - Processes the image (e.g., extracts features like bone density or detects anomalies).\n",
            "\n",
            "2. **DiagnosisAgent**:\n",
            "   - Provides an initial diagnosis based on the extracted features.\n",
            "\n",
            "3. **ReportGenerationAgent**:\n",
            "   - Generates a structured report summarizing the analysis and diagnosis.\n",
            "\n",
            "4. **SupervisorAgent**:\n",
            "   - Orchestrates the workflow by passing results between the agents.\n",
            "\n",
            "---\n",
            "\n",
            "### Notes:\n",
            "- Replace `\"sample_x_ray_image.png\"` with the path to an actual X-ray image file.\n",
            "- You can expand the logic within each agent for more advanced image analysis using machine learning models.\n",
            "- This code exemplifies modularity, making it easy to augment or replace components as needed.\n",
            "\n",
            "Let me know if you have any questions or need further assistance! ðŸš€\n",
            "User: q\n",
            "Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## X ray image analysis\n"
      ],
      "metadata": {
        "id": "cxWbmFsav52T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "### Code: X-Ray Image Analysis with LangGraph\n",
        "from langgraph import LangGraph, Agent, Supervisor\n",
        "from PIL import Image\n",
        "\n",
        "# Sample agents for the X-Ray Workflow\n",
        "class ImageProcessingAgent(Agent):\n",
        "    def process(self, x_ray_image: Image.Image):\n",
        "        # Simulate feature extraction (e.g., bone structure detection)\n",
        "        features = {\"bone_density\": \"medium\", \"fracture\": \"none\", \"anomalies\": [\"shadow in lung\"]}\n",
        "        print(f\"ImageProcessingAgent: Extracted features {features}\")\n",
        "        return features\n",
        "\n",
        "class DiagnosisAgent(Agent):\n",
        "    def process(self, features: dict):\n",
        "        # Simulate diagnosis based on extracted features\n",
        "        diagnosis = \"Possible Pneumonia due to lung shadow. No fractures detected.\"\n",
        "        print(f\"DiagnosisAgent: Diagnosis result - {diagnosis}\")\n",
        "        return diagnosis\n",
        "\n",
        "class ReportGenerationAgent(Agent):\n",
        "    def process(self, diagnosis: str):\n",
        "        # Simulate report generation\n",
        "        report = f\"X-Ray Report:\\nDiagnosis: {diagnosis}\\nAction: Follow up with a physician for further tests.\"\n",
        "        print(f\"ReportGenerationAgent: Generated Report - \\n{report}\")\n",
        "        return report\n",
        "\n",
        "\n",
        "# Supervisor coordinating all agents\n",
        "class SupervisorAgent(Supervisor):\n",
        "    def supervise(self, x_ray_image: Image.Image):\n",
        "        print(\"SupervisorAgent: Starting X-Ray image analysis workflow...\\n\")\n",
        "\n",
        "        # Step 1: Process the image\n",
        "        processing_agent = ImageProcessingAgent()\n",
        "        extracted_features = processing_agent.process(x_ray_image)\n",
        "\n",
        "        # Step 2: Diagnosis from features\n",
        "        diagnosis_agent = DiagnosisAgent()\n",
        "        diagnosis = diagnosis_agent.process(extracted_features)\n",
        "\n",
        "        # Step 3: Generate report\n",
        "        report_agent = ReportGenerationAgent()\n",
        "        final_report = report_agent.process(diagnosis)\n",
        "\n",
        "        print(\"\\nSupervisorAgent: Workflow complete!\")\n",
        "        return final_report\n",
        "\n",
        "\n",
        "# Example run\n",
        "if __name__ == \"__main__\":\n",
        "    # Load a sample X-Ray image (replace with actual image path)\n",
        "    x_ray_image_path = \"sample_x_ray_image.png\"  # Replace with the actual image file path\n",
        "    try:\n",
        "        x_ray_image = Image.open(x_ray_image_path).convert(\"L\")  # Convert to grayscale for simplicity\n",
        "        supervisor = SupervisorAgent()\n",
        "\n",
        "        # Start the workflow\n",
        "        xray_analysis_report = supervisor.supervise(x_ray_image)\n",
        "\n",
        "        # Output the final report\n",
        "        print(\"\\nFinal Report:\\n\", xray_analysis_report)\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")"
      ],
      "metadata": {
        "id": "JuG6EbeBv8In",
        "outputId": "0fe654af-f8be-4290-ce96-1e7cefad691d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'LangGraph' from 'langgraph' (unknown location)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-11-1564318931.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### Code: X-Ray Image Analysis with LangGraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlanggraph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLangGraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSupervisor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Sample agents for the X-Ray Workflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'LangGraph' from 'langgraph' (unknown location)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## gemini\n"
      ],
      "metadata": {
        "id": "HyoVgGAEpzIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U \"langchain[google-genai]\""
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tm1iTktkp0j9",
        "outputId": "745cf1e6-a20f-45b1-e31a-b6612bf108f4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain[google-genai] in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain[google-genai]) (0.3.65)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain[google-genai]) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain[google-genai]) (0.3.45)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain[google-genai]) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain[google-genai]) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain[google-genai]) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain[google-genai]) (6.0.2)\n",
            "Collecting langchain-google-genai (from langchain[google-genai])\n",
            "  Downloading langchain_google_genai-2.1.5-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain[google-genai]) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain[google-genai]) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain[google-genai]) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain[google-genai]) (4.14.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain[google-genai]) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain[google-genai]) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain[google-genai]) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain[google-genai]) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain[google-genai]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain[google-genai]) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain[google-genai]) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain[google-genai]) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain[google-genai]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain[google-genai]) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain[google-genai]) (2025.6.15)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain[google-genai]) (3.2.3)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai->langchain[google-genai])\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai->langchain[google-genai])\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (5.29.5)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain[google-genai]) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain[google-genai]) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain[google-genai]) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain[google-genai]) (3.0.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (1.73.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (4.9.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain[google-genai]) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (0.6.1)\n",
            "Downloading langchain_google_genai-2.1.5-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, google-ai-generativelanguage, langchain-google-genai\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed filetype-1.2.0 google-ai-generativelanguage-0.6.18 langchain-google-genai-2.1.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "02d86e3f1fc8441b804b82841d4d1d51"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCXp230h__4BovmnNDxBWwjIfbyZTCvUKA\"\n",
        "\n",
        "llm = init_chat_model(\"google_genai:gemini-2.0-flash\")"
      ],
      "metadata": {
        "id": "dJDh5RUFp4tV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
        "\n",
        "\n",
        "# The first argument is the unique node name\n",
        "# The second argument is the function or object that will be called whenever\n",
        "# the node is used.\n",
        "graph_builder.add_node(\"chatbot\", chatbot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "WMW9pjdTp_8X",
        "outputId": "e69df1d7-8a3c-45a3-ba91-c3f34517d8ff"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langgraph.graph.state:Adding a node to a graph that has already been compiled. This will not be reflected in the compiled graph.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Node `chatbot` already present.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-16-2732917368.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# The second argument is the function or object that will be called whenever\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# the node is used.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mgraph_builder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"chatbot\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchatbot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/graph/state.py\u001b[0m in \u001b[0;36madd_node\u001b[0;34m(self, node, action, defer, metadata, input, retry, cache_policy, destinations)\u001b[0m\n\u001b[1;32m    373\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Node `{node}` already present.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEND\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSTART\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Node `{node}` is reserved.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Node `chatbot` already present."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder.add_edge(START, \"chatbot\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nceoDKDvqD0B",
        "outputId": "d5d201e5-6e86-4217-eb39-2a0a82df5919"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x791ae2ed8d50>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "5Lj9jQCFqHdy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stream_graph_updates(user_input: str):\n",
        "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
        "        for value in event.values():\n",
        "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
        "\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        user_input = input(\"User: \")\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "        stream_graph_updates(user_input)\n",
        "    except:\n",
        "        # fallback if input() is not available\n",
        "        user_input = \"What do you know about LangGraph?\"\n",
        "        print(\"User: \" + user_input)\n",
        "        stream_graph_updates(user_input)\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WXpN8UFgqLCp",
        "outputId": "78186687-581d-4863-dd7a-995c143221b3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: I want to learn about multi agent in langchain\n",
            "Assistant: Okay, let's dive into multi-agent systems in Langchain. This is a powerful area that allows you to build complex applications where multiple \"agents\" collaborate to solve problems.\n",
            "\n",
            "**What are Multi-Agent Systems?**\n",
            "\n",
            "In essence, a multi-agent system (MAS) is a system composed of multiple intelligent agents that interact with each other and their environment.  Each agent has its own goals, knowledge, and capabilities. The agents communicate, coordinate, and negotiate to achieve individual or collective goals.\n",
            "\n",
            "**Why Use Multi-Agent Systems in Langchain?**\n",
            "\n",
            "*   **Complex Problem Solving:** Decompose complex tasks into smaller, more manageable sub-tasks that can be handled by specialized agents.\n",
            "*   **Specialization:** Different agents can be equipped with different tools, knowledge, and expertise. This allows you to leverage the strengths of each agent.\n",
            "*   **Collaboration:** Agents can work together to achieve a common goal, sharing information and coordinating their actions.\n",
            "*   **Scalability:** Adding more agents to the system can potentially scale the system's capabilities.\n",
            "*   **Flexibility and Adaptability:** Multi-agent systems can be designed to adapt to changing environments and requirements.\n",
            "*   **Mimicking Real-World Interactions:**  Many real-world scenarios involve multiple actors with different roles and responsibilities. MAS can model these scenarios more naturally.\n",
            "\n",
            "**Key Concepts in Langchain Multi-Agent Systems**\n",
            "\n",
            "1.  **Agents:**\n",
            "    *   The core building blocks.  An agent is an entity that can perceive its environment, make decisions, and take actions.\n",
            "    *   In Langchain, an agent typically consists of:\n",
            "        *   **LLM (Language Model):**  The brain of the agent.  It uses a language model (e.g., GPT-3.5, GPT-4) to process information, reason, and generate actions.\n",
            "        *   **Tools:** The agent's capabilities.  Tools can be anything from a search engine to a calculator to a database connection.\n",
            "        *   **Agent Executor:**  Manages the execution of the agent's actions, calling the appropriate tools and feeding the results back to the LLM.\n",
            "        *   **Prompt:** Instructions given to the LLM to guide its behavior.\n",
            "    *   **Types of Agents:**\n",
            "        *   **Zero-shot react description:**  Uses only the tool's description to decide which tool to use.\n",
            "        *   **React docstore:** Accesses a document store (like Wikipedia) to answer questions.\n",
            "        *   **Self-ask with search:** Asks clarifying questions to a search engine to gather more information.\n",
            "        *   **Conversational react description:** Designed for conversational interactions, remembering past turns.\n",
            "        *   **Plan-and-execute:** First plans out the steps to take, then executes those steps.\n",
            "\n",
            "2.  **Tools:**\n",
            "    *   Functions or services that agents can use to interact with the world.\n",
            "    *   Examples:\n",
            "        *   `SerpAPIWrapper`:  For searching the internet.\n",
            "        *   `WikipediaAPIWrapper`: For accessing Wikipedia.\n",
            "        *   `Calculator`:  For performing calculations.\n",
            "        *   `PythonREPLTool`:  For executing Python code.\n",
            "        *   Custom Tools: You can define your own tools to interact with specific APIs or data sources.\n",
            "\n",
            "3.  **Agent Executor:**\n",
            "    *   The component that orchestrates the agent's actions.\n",
            "    *   It takes the agent's decisions (which tool to use and with what input), executes the tool, and passes the results back to the agent's LLM.\n",
            "    *   It manages the agent's \"thought process\" by keeping track of the agent's observations and actions.\n",
            "\n",
            "4.  **Memory:**\n",
            "    *   Agents often need to remember past interactions to make informed decisions.\n",
            "    *   Langchain provides various memory implementations, such as:\n",
            "        *   `ConversationBufferMemory`: Stores the entire conversation history.\n",
            "        *   `ConversationSummaryMemory`: Summarizes the conversation history to save space.\n",
            "        *   `ConversationBufferWindowMemory`: Stores a limited number of recent turns in the conversation.\n",
            "\n",
            "5.  **Chains:**\n",
            "    *   Sequences of calls to LLMs or other utilities.\n",
            "    *   Agents often use chains to perform specific tasks, such as formatting the output of a tool or summarizing a document.\n",
            "\n",
            "6. **Planning and Execution:**\n",
            "   * Some advanced multi-agent systems involve a planning stage where agents collaborate to create a plan of action before executing it. This can improve coordination and efficiency.\n",
            "\n",
            "**Basic Workflow of an Agent:**\n",
            "\n",
            "1.  **Receive Input:** The agent receives a user query or task.\n",
            "2.  **Observe:** The agent analyzes the input and its current state (including memory).\n",
            "3.  **Think:** The LLM processes the information and decides on the next action.\n",
            "4.  **Act:** The agent selects a tool and provides input to the tool.\n",
            "5.  **Observe (Result):** The agent receives the output from the tool.\n",
            "6.  **Repeat:** Steps 3-5 are repeated until the agent has achieved its goal or reached a stopping condition.\n",
            "7.  **Respond:** The agent provides a final answer or result to the user.\n",
            "\n",
            "**Example:  A Simple Agent Using a Search Engine**\n",
            "\n",
            "```python\n",
            "from langchain.agents import initialize_agent, Tool\n",
            "from langchain.agents import AgentType\n",
            "from langchain.llms import OpenAI\n",
            "from langchain.utilities import SerpAPIWrapper\n",
            "import os\n",
            "\n",
            "# Set your OpenAI API key (replace with your actual key)\n",
            "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\"  # Replace with your API key\n",
            "# Set your SerpAPI key (replace with your actual key)\n",
            "os.environ[\"SERPAPI_API_KEY\"] = \"YOUR_SERPAPI_API_KEY\"\n",
            "\n",
            "# Initialize the LLM (e.g., OpenAI's GPT-3.5)\n",
            "llm = OpenAI(temperature=0)\n",
            "\n",
            "# Define the tools the agent can use (in this case, a search engine)\n",
            "search = SerpAPIWrapper()\n",
            "tools = [\n",
            "    Tool(\n",
            "        name=\"Search\",\n",
            "        func=search.run,\n",
            "        description=\"useful for when you need to answer questions about current events. You should ask very specific questions\",\n",
            "    )\n",
            "]\n",
            "\n",
            "# Initialize the agent\n",
            "agent = initialize_agent(\n",
            "    tools,\n",
            "    llm,\n",
            "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
            "    verbose=True,\n",
            ")\n",
            "\n",
            "# Run the agent\n",
            "query = \"What is the current temperature in London?\"\n",
            "response = agent.run(query)\n",
            "print(response)\n",
            "```\n",
            "\n",
            "**Explanation of the Code:**\n",
            "\n",
            "1.  **Import Libraries:** Imports necessary modules from Langchain.\n",
            "2.  **Set API Keys:**  Sets the OpenAI and SerpAPI API keys as environment variables.  **Important:**  Never hardcode API keys directly in your code. Use environment variables or a secrets management system.\n",
            "3.  **Initialize LLM:** Creates an instance of the OpenAI language model.  `temperature=0` makes the LLM more deterministic.\n",
            "4.  **Define Tools:** Creates a `Tool` object that represents the search engine.  The `description` is crucial; it tells the agent when to use this tool.\n",
            "5.  **Initialize Agent:**\n",
            "    *   `initialize_agent` creates the agent.\n",
            "    *   `tools`:  The list of tools the agent can use.\n",
            "    *   `llm`:  The language model.\n",
            "    *   `agent`: Specifies the type of agent (e.g., `AgentType.ZERO_SHOT_REACT_DESCRIPTION`).  This agent type uses only the tool descriptions to decide which tool to use.\n",
            "    *   `verbose=True`:  Prints the agent's thought process to the console, which is helpful for debugging.\n",
            "6.  **Run Agent:**\n",
            "    *   `agent.run(query)` executes the agent with the given query.\n",
            "    *   The agent will use the LLM to decide whether to use the search tool.  If it decides to use the search tool, it will pass the query to the search engine and then use the LLM to generate a final answer based on the search results.\n",
            "\n",
            "**Important Considerations:**\n",
            "\n",
            "*   **API Keys:**  You'll need API keys for the LLM (e.g., OpenAI) and any tools you use (e.g., SerpAPI, Google Search).\n",
            "*   **Prompt Engineering:**  The prompt you provide to the agent significantly impacts its behavior.  Craft clear and specific prompts to guide the agent's reasoning.\n",
            "*   **Tool Descriptions:** The descriptions of your tools are critical for the agent to understand when and how to use them.\n",
            "*   **Error Handling:** Implement robust error handling to catch exceptions and prevent the agent from crashing.\n",
            "*   **Security:** Be mindful of security risks when using external tools and APIs.  Sanitize inputs and validate outputs to prevent vulnerabilities.\n",
            "*   **Cost:** Using LLMs can be expensive.  Monitor your API usage and set limits to avoid unexpected charges.\n",
            "\n",
            "**More Advanced Multi-Agent Scenarios**\n",
            "\n",
            "*   **Chatbots with Multiple Personalities:** Create a chatbot with different agents representing different personalities or areas of expertise.\n",
            "*   **Task Decomposition and Coordination:**  Use multiple agents to break down a complex task into smaller sub-tasks and coordinate their execution.\n",
            "*   **Negotiation and Collaboration:**  Develop agents that can negotiate with each other to reach agreements or solve problems collaboratively.\n",
            "*   **Planning and Execution:**  Agents can work together to create a plan of action before executing it.\n",
            "*   **Simulations:**  Model real-world scenarios with multiple interacting agents.\n",
            "\n",
            "**Example: Two Agents with Different Roles (Conceptual)**\n",
            "\n",
            "Imagine you want to build a system to plan a trip.  You could have:\n",
            "\n",
            "*   **Planner Agent:** Responsible for creating the itinerary, considering user preferences and constraints.  This agent might use tools for searching for flights, hotels, and activities.\n",
            "*   **Booking Agent:** Responsible for making reservations for flights, hotels, and activities.  This agent would need access to booking APIs.\n",
            "\n",
            "The Planner Agent would first create a plan, and then the Booking Agent would execute the plan by making the necessary reservations.\n",
            "\n",
            "**Where to Go Next:**\n",
            "\n",
            "*   **Langchain Documentation:**  The official Langchain documentation is the best resource for learning about multi-agent systems.  Look for the sections on agents, tools, and agent executors.\n",
            "*   **Langchain Examples:**  Explore the Langchain examples repository for practical examples of multi-agent systems.\n",
            "*   **Research Papers:**  Read research papers on multi-agent systems to gain a deeper understanding of the underlying concepts and algorithms.\n",
            "\n",
            "**Important Notes on Langchain Updates:**\n",
            "\n",
            "The Langchain library is under active development, so the API may change. Always refer to the latest documentation for the most up-to-date information.\n",
            "\n",
            "This is a starting point.  Multi-agent systems are a complex and evolving field.  Experiment with different approaches and tools to find what works best for your specific use case. Good luck!\n",
            "User: can you explain your code on which you are built to a leyman\n",
            "Assistant: Okay, let's break down how I work in a way that's easy to understand, without getting too technical.\n",
            "\n",
            "**Imagine I'm a really, really complicated recipe book.**\n",
            "\n",
            "That's the best analogy.  Here's how the recipe book works:\n",
            "\n",
            "*   **The Recipes (My Training Data):** This is the core of everything.  I've read (or been \"trained\" on) a massive collection of text and code. Think of it as millions of cookbooks filled with different recipes for writing, answering questions, translating, summarizing, and much more.  This includes:\n",
            "    *   **Books:** Novels, textbooks, articles, etc.\n",
            "    *   **Websites:** Wikipedia, news sites, blogs, forums, etc.\n",
            "    *   **Code:** Examples of Python, Java, C++, and other programming languages.\n",
            "    *   **Conversations:** Examples of people talking to each other.\n",
            "\n",
            "    The more recipes I have, the better I become at \"cooking\" up the right response.\n",
            "\n",
            "*   **The Index (My Model):** This isn't just a simple list of ingredients. It's a complex map of relationships between words, concepts, and ideas that I learned from the training data.  It's like a super-advanced index that not only tells me *where* a word is used, but also *how* it's used, *what* words usually appear around it, and *what* the overall meaning is.  This is the \"model\" part.  It's a mathematical representation of all the patterns I've learned.\n",
            "\n",
            "*   **The Chef (My Algorithm/Software):** This is the \"brain\" that uses the recipe book (training data) and the index (model) to create something new.  When you ask me a question, the chef does the following:\n",
            "\n",
            "    1.  **Understands the Request:**  The chef carefully reads your question, breaking it down into key words and phrases. It tries to figure out what you're really asking.\n",
            "\n",
            "    2.  **Looks Up Relevant Recipes:** Based on the keywords in your question, the chef searches the index (model) to find the most relevant \"recipes\" (patterns and information) from the training data.\n",
            "\n",
            "    3.  **Combines and Adapts:** The chef doesn't just copy and paste a recipe. Instead, it combines the information from multiple recipes, adapts them to the specific question, and generates a new, original answer.\n",
            "\n",
            "    4.  **Outputs the Result:** The chef presents the finished \"dish\" â€“ my answer â€“ to you.\n",
            "\n",
            "**Key Concepts Simplified:**\n",
            "\n",
            "*   **Training:**  The process of feeding me lots of data (the recipes) so I can learn the patterns and relationships between words and concepts.\n",
            "*   **Model:** The complex index that stores all the information I've learned during training.  It's like a highly organized and interconnected map of knowledge.\n",
            "*   **Algorithm:** The software that uses the model to understand your questions and generate answers.  It's the chef that does the actual \"cooking.\"\n",
            "*   **Neural Networks:**  This is the type of architecture used to build my model. Think of it as a network of interconnected nodes (like neurons in a brain) that process information.  The connections between these nodes are strengthened or weakened during training, allowing me to learn complex patterns.\n",
            "\n",
            "**Important Points:**\n",
            "\n",
            "*   **I Don't \"Think\" Like a Human:** I don't have consciousness, emotions, or personal beliefs. I'm a machine that's been trained to recognize patterns in data and generate text based on those patterns.\n",
            "*   **I Can Make Mistakes:** Because I'm trained on data created by humans, I can sometimes reflect biases present in that data. I can also get things wrong if the training data is incomplete or inaccurate.\n",
            "*   **I'm Constantly Evolving:** My creators are constantly working to improve my training data, model, and algorithms. This means I'm getting better and more capable over time.\n",
            "\n",
            "**In a nutshell, I'm like a super-advanced recipe book that can understand your requests, find the right ingredients, and cook up a new and original answer just for you.**\n",
            "\n",
            "Is that easier to understand? Let me know if you have any other questions.\n",
            "User: quit\n",
            "Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## supervisor"
      ],
      "metadata": {
        "id": "fVoB5-gMwXMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langgraph-supervisor"
      ],
      "metadata": {
        "collapsed": true,
        "id": "65UASIdxwZw8",
        "outputId": "fd19fc23-605b-4ee7-db3b-553c6281b283",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph-supervisor\n",
            "  Downloading langgraph_supervisor-0.0.27-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: langgraph>=0.3.5 in /usr/local/lib/python3.11/dist-packages (from langgraph-supervisor) (0.4.8)\n",
            "Requirement already satisfied: langgraph-prebuilt>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from langgraph-supervisor) (0.2.2)\n",
            "Requirement already satisfied: langchain-core>=0.3.40 in /usr/local/lib/python3.11/dist-packages (from langgraph-supervisor) (0.3.65)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.3.40->langgraph-supervisor) (0.3.45)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.3.40->langgraph-supervisor) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.3.40->langgraph-supervisor) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.3.40->langgraph-supervisor) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.3.40->langgraph-supervisor) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.3.40->langgraph-supervisor) (4.14.0)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.3.40->langgraph-supervisor) (2.11.7)\n",
            "Requirement already satisfied: langgraph-checkpoint>=2.0.26 in /usr/local/lib/python3.11/dist-packages (from langgraph>=0.3.5->langgraph-supervisor) (2.1.0)\n",
            "Requirement already satisfied: langgraph-sdk>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph>=0.3.5->langgraph-supervisor) (0.1.70)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph>=0.3.5->langgraph-supervisor) (3.5.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.3.40->langgraph-supervisor) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint>=2.0.26->langgraph>=0.3.5->langgraph-supervisor) (1.10.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph>=0.3.5->langgraph-supervisor) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph>=0.3.5->langgraph-supervisor) (3.10.18)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core>=0.3.40->langgraph-supervisor) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core>=0.3.40->langgraph-supervisor) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core>=0.3.40->langgraph-supervisor) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core>=0.3.40->langgraph-supervisor) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core>=0.3.40->langgraph-supervisor) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core>=0.3.40->langgraph-supervisor) (0.4.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph>=0.3.5->langgraph-supervisor) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph>=0.3.5->langgraph-supervisor) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph>=0.3.5->langgraph-supervisor) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph>=0.3.5->langgraph-supervisor) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph>=0.3.5->langgraph-supervisor) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.3.45->langchain-core>=0.3.40->langgraph-supervisor) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.3.45->langchain-core>=0.3.40->langgraph-supervisor) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph>=0.3.5->langgraph-supervisor) (1.3.1)\n",
            "Downloading langgraph_supervisor-0.0.27-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: langgraph-supervisor\n",
            "Successfully installed langgraph-supervisor-0.0.27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph_supervisor import create_supervisor\n",
        "\n",
        "def book_hotel(hotel_name: str):\n",
        "    \"\"\"Book a hotel\"\"\"\n",
        "    return f\"Successfully booked a stay at {hotel_name}.\"\n",
        "\n",
        "def book_flight(from_airport: str, to_airport: str):\n",
        "    \"\"\"Book a flight\"\"\"\n",
        "    return f\"Successfully booked a flight from {from_airport} to {to_airport}.\"\n",
        "\n",
        "flight_assistant = create_react_agent(\n",
        "    model=\"openai:gpt-4o\",\n",
        "    tools=[book_flight],\n",
        "    prompt=\"You are a flight booking assistant\",\n",
        "    name=\"flight_assistant\"\n",
        ")\n",
        "\n",
        "hotel_assistant = create_react_agent(\n",
        "    model=\"openai:gpt-4o\",\n",
        "    tools=[book_hotel],\n",
        "    prompt=\"You are a hotel booking assistant\",\n",
        "    name=\"hotel_assistant\"\n",
        ")\n",
        "\n",
        "supervisor = create_supervisor(\n",
        "    agents=[flight_assistant, hotel_assistant],\n",
        "    model=ChatOpenAI(model=\"gpt-4o\"),\n",
        "    prompt=(\n",
        "        \"You manage a hotel booking assistant and a\"\n",
        "        \"flight booking assistant. Assign work to them.\"\n",
        "    )\n",
        ").compile()\n",
        "\n",
        "for chunk in supervisor.stream(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": \"book a flight from BOS to JFK and a stay at McKittrick Hotel\"\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "):\n",
        "    print(chunk)\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "O5wUxeF4we2h",
        "outputId": "1d799dad-c6c6-485f-b63e-3e13bd30f6aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OpenAIError",
          "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-13-1040564946.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34mf\"Successfully booked a flight from {from_airport} to {to_airport}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m flight_assistant = create_react_agent(\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"openai:gpt-4o\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mtools\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbook_flight\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/prebuilt/chat_agent_executor.py\u001b[0m in \u001b[0;36mcreate_react_agent\u001b[0;34m(model, tools, prompt, response_format, pre_model_hook, post_model_hook, state_schema, config_schema, checkpointer, store, interrupt_before, interrupt_after, debug, version, name)\u001b[0m\n\u001b[1;32m    440\u001b[0m             )\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseChatModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_chat_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[0mtool_calling_enabled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtool_classes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chat_models/base.py\u001b[0m in \u001b[0;36minit_chat_model\u001b[0;34m(model, model_provider, configurable_fields, config_prefix, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconfigurable_fields\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         return _init_chat_model_helper(\n\u001b[0m\u001b[1;32m    323\u001b[0m             \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_provider\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_provider\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chat_models/base.py\u001b[0m in \u001b[0;36m_init_chat_model_helper\u001b[0;34m(model, model_provider, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmodel_provider\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"anthropic\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0m_check_pkg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"langchain_anthropic\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/load/serializable.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;34m\"\"\"\"\"\"\u001b[0m  \u001b[0;31m# noqa: D419\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py\u001b[0m in \u001b[0;36mvalidate_environment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    688\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_get_default_httpx_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopenai_api_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m             }\n\u001b[0;32m--> 690\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mclient_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msync_specific\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompletions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_client\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mapi_key\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             raise OpenAIError(\n\u001b[0m\u001b[1;32m    127\u001b[0m                 \u001b[0;34m\"The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             )\n",
            "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import AzureChatOpenAI\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph_supervisor import create_supervisor\n",
        "\n",
        "# Define tools\n",
        "def book_hotel(hotel_name: str):\n",
        "    \"\"\"Book a hotel\"\"\"\n",
        "    return f\"Successfully booked a stay at {hotel_name}.\"\n",
        "\n",
        "def book_flight(from_airport: str, to_airport: str):\n",
        "    \"\"\"Book a flight\"\"\"\n",
        "    return f\"Successfully booked a flight from {from_airport} to {to_airport}.\"\n",
        "\n",
        "\n",
        "# Azure OpenAI model configuration\n",
        "azure_openai_config = {\n",
        "    \"api_key\": \"1lOkjRo9bsDnbAE2v1qVagkmEj6mT111wak1spzwGQMDsqFoVT1aJQQJ99BDAC5RqLJXJ3w3AAABACOGNvwZ\",\n",
        "    \"api_version\": \"2024-12-01-preview\",  # or your specific version\n",
        "    \"azure_endpoint\": \"https://agentic-accelerator-pod-openai-we.openai.azure.com/\",\n",
        "    \"deployment_name\": \"gpt-4o\",  # must be a chat model like gpt-35-turbo or gpt-4\n",
        "\n",
        "}\n",
        "\n",
        "# Create assistants using AzureChatOpenAI\n",
        "llm = AzureChatOpenAI(\n",
        "    deployment_name=azure_openai_config[\"deployment_name\"],\n",
        "    openai_api_key=azure_openai_config[\"api_key\"],\n",
        "    openai_api_version=azure_openai_config[\"api_version\"],\n",
        "    azure_endpoint=azure_openai_config[\"azure_endpoint\"]\n",
        ")\n",
        "\n",
        "flight_assistant = create_react_agent(\n",
        "    model=llm,\n",
        "    tools=[book_flight],\n",
        "    prompt=\"You are a flight booking assistant\",\n",
        "    name=\"flight_assistant\"\n",
        ")\n",
        "\n",
        "hotel_assistant = create_react_agent(\n",
        "    model=llm,\n",
        "    tools=[book_hotel],\n",
        "    prompt=\"You are a hotel booking assistant\",\n",
        "    name=\"hotel_assistant\"\n",
        ")\n",
        "\n",
        "supervisor = create_supervisor(\n",
        "    agents=[flight_assistant, hotel_assistant],\n",
        "    model=llm,\n",
        "    prompt=\"You manage a hotel booking assistant and a flight booking assistant. Assign work to them.\"\n",
        ").compile()\n",
        "\n",
        "# Run the conversation\n",
        "for chunk in supervisor.stream(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": \"book a flight from BOS to JFK and a stay at McKittrick Hotel\"\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "):\n",
        "    print(chunk)\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "id": "9vd2P4UrzafH",
        "outputId": "35be4162-9649-4446-b780-6b545de94635",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'supervisor': {'messages': [HumanMessage(content='book a flight from BOS to JFK and a stay at McKittrick Hotel', additional_kwargs={}, response_metadata={}, id='7f8c03d6-d8f2-4335-a935-a0d1dca7bcc3'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_xgbD0mYSoBon6uMM1sbVg1tc', 'function': {'arguments': '{}', 'name': 'transfer_to_flight_assistant'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 100, 'total_tokens': 115, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ee1d74bde0', 'id': 'chatcmpl-Bk78eWuD9n6DFbCJsiAQ58a3w6ftv', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, name='supervisor', id='run--e73a245e-a314-47de-867f-1fba17230c36-0', tool_calls=[{'name': 'transfer_to_flight_assistant', 'args': {}, 'id': 'call_xgbD0mYSoBon6uMM1sbVg1tc', 'type': 'tool_call'}], usage_metadata={'input_tokens': 100, 'output_tokens': 15, 'total_tokens': 115, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='Successfully transferred to flight_assistant', name='transfer_to_flight_assistant', id='1671d1ea-a8ba-4a49-81e4-2c19e8653aed', tool_call_id='call_xgbD0mYSoBon6uMM1sbVg1tc')]}}\n",
            "\n",
            "\n",
            "{'flight_assistant': {'messages': [AIMessage(content=\"Your flight from BOS (Boston Logan International Airport) to JFK (John F. Kennedy International Airport) has been successfully booked. For the stay at McKittrick Hotel, you might need to coordinate separately or use a booking platform. Let me know if you'd like further assistance with hotel arrangements!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 61, 'prompt_tokens': 155, 'total_tokens': 216, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ee1d74bde0', 'id': 'chatcmpl-Bk78fjCgyYrF7TNkIge4X2nTInLTC', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, name='flight_assistant', id='run--24ef1365-60d4-4047-9909-ad2c93d30972-0', usage_metadata={'input_tokens': 155, 'output_tokens': 61, 'total_tokens': 216, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content='Transferring back to supervisor', additional_kwargs={}, response_metadata={'__is_handoff_back': True}, name='flight_assistant', id='30959da0-d6da-41e2-83f4-47a95ee40229', tool_calls=[{'name': 'transfer_back_to_supervisor', 'args': {}, 'id': 'f809d0e0-bb4b-469c-a223-e67617427670', 'type': 'tool_call'}]), ToolMessage(content='Successfully transferred back to supervisor', name='transfer_back_to_supervisor', id='d6ea3bdd-04b5-4fc2-940c-5a2e01e9298d', tool_call_id='f809d0e0-bb4b-469c-a223-e67617427670')]}}\n",
            "\n",
            "\n",
            "{'supervisor': {'messages': [HumanMessage(content='book a flight from BOS to JFK and a stay at McKittrick Hotel', additional_kwargs={}, response_metadata={}, id='7f8c03d6-d8f2-4335-a935-a0d1dca7bcc3'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_xgbD0mYSoBon6uMM1sbVg1tc', 'function': {'arguments': '{}', 'name': 'transfer_to_flight_assistant'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 100, 'total_tokens': 115, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ee1d74bde0', 'id': 'chatcmpl-Bk78eWuD9n6DFbCJsiAQ58a3w6ftv', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, name='supervisor', id='run--e73a245e-a314-47de-867f-1fba17230c36-0', tool_calls=[{'name': 'transfer_to_flight_assistant', 'args': {}, 'id': 'call_xgbD0mYSoBon6uMM1sbVg1tc', 'type': 'tool_call'}], usage_metadata={'input_tokens': 100, 'output_tokens': 15, 'total_tokens': 115, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='Successfully transferred to flight_assistant', name='transfer_to_flight_assistant', id='1671d1ea-a8ba-4a49-81e4-2c19e8653aed', tool_call_id='call_xgbD0mYSoBon6uMM1sbVg1tc'), AIMessage(content=\"Your flight from BOS (Boston Logan International Airport) to JFK (John F. Kennedy International Airport) has been successfully booked. For the stay at McKittrick Hotel, you might need to coordinate separately or use a booking platform. Let me know if you'd like further assistance with hotel arrangements!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 61, 'prompt_tokens': 155, 'total_tokens': 216, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ee1d74bde0', 'id': 'chatcmpl-Bk78fjCgyYrF7TNkIge4X2nTInLTC', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, name='flight_assistant', id='run--24ef1365-60d4-4047-9909-ad2c93d30972-0', usage_metadata={'input_tokens': 155, 'output_tokens': 61, 'total_tokens': 216, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content='Transferring back to supervisor', additional_kwargs={}, response_metadata={'__is_handoff_back': True}, name='flight_assistant', id='30959da0-d6da-41e2-83f4-47a95ee40229', tool_calls=[{'name': 'transfer_back_to_supervisor', 'args': {}, 'id': 'f809d0e0-bb4b-469c-a223-e67617427670', 'type': 'tool_call'}]), ToolMessage(content='Successfully transferred back to supervisor', name='transfer_back_to_supervisor', id='d6ea3bdd-04b5-4fc2-940c-5a2e01e9298d', tool_call_id='f809d0e0-bb4b-469c-a223-e67617427670'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_G8hFci5rIjjleTddUnHy0yDg', 'function': {'arguments': '{}', 'name': 'transfer_to_hotel_assistant'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 249, 'total_tokens': 264, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ee1d74bde0', 'id': 'chatcmpl-Bk78gBAmmepOP9gh70jm97OQ4cOr0', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, name='supervisor', id='run--6bc1aaeb-8ccf-486a-b9a1-6bfe022b71aa-0', tool_calls=[{'name': 'transfer_to_hotel_assistant', 'args': {}, 'id': 'call_G8hFci5rIjjleTddUnHy0yDg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 249, 'output_tokens': 15, 'total_tokens': 264, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='Successfully transferred to hotel_assistant', name='transfer_to_hotel_assistant', id='e41f2c8c-be4d-4b21-b92b-eb263c156f3e', tool_call_id='call_G8hFci5rIjjleTddUnHy0yDg')]}}\n",
            "\n",
            "\n",
            "{'hotel_assistant': {'messages': [AIMessage(content='Your stay at the McKittrick Hotel has been successfully booked. Let me know if you require any additional assistance!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 294, 'total_tokens': 320, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ee1d74bde0', 'id': 'chatcmpl-Bk78iwtyRDFfn3D0FUj6tvUNDPJQE', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, name='hotel_assistant', id='run--a05a3fe9-67ed-4ebb-9de8-55a1310ab42c-0', usage_metadata={'input_tokens': 294, 'output_tokens': 26, 'total_tokens': 320, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content='Transferring back to supervisor', additional_kwargs={}, response_metadata={'__is_handoff_back': True}, name='hotel_assistant', id='3473d686-4e59-4d31-a4c6-5aadbf736771', tool_calls=[{'name': 'transfer_back_to_supervisor', 'args': {}, 'id': 'fca2ca11-926c-493f-8b32-6be25b6e5674', 'type': 'tool_call'}]), ToolMessage(content='Successfully transferred back to supervisor', name='transfer_back_to_supervisor', id='cab3b72d-a5ba-42c0-a5d1-bc2c13f0a3b7', tool_call_id='fca2ca11-926c-493f-8b32-6be25b6e5674')]}}\n",
            "\n",
            "\n",
            "{'supervisor': {'messages': [HumanMessage(content='book a flight from BOS to JFK and a stay at McKittrick Hotel', additional_kwargs={}, response_metadata={}, id='7f8c03d6-d8f2-4335-a935-a0d1dca7bcc3'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_xgbD0mYSoBon6uMM1sbVg1tc', 'function': {'arguments': '{}', 'name': 'transfer_to_flight_assistant'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 100, 'total_tokens': 115, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ee1d74bde0', 'id': 'chatcmpl-Bk78eWuD9n6DFbCJsiAQ58a3w6ftv', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, name='supervisor', id='run--e73a245e-a314-47de-867f-1fba17230c36-0', tool_calls=[{'name': 'transfer_to_flight_assistant', 'args': {}, 'id': 'call_xgbD0mYSoBon6uMM1sbVg1tc', 'type': 'tool_call'}], usage_metadata={'input_tokens': 100, 'output_tokens': 15, 'total_tokens': 115, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='Successfully transferred to flight_assistant', name='transfer_to_flight_assistant', id='1671d1ea-a8ba-4a49-81e4-2c19e8653aed', tool_call_id='call_xgbD0mYSoBon6uMM1sbVg1tc'), AIMessage(content=\"Your flight from BOS (Boston Logan International Airport) to JFK (John F. Kennedy International Airport) has been successfully booked. For the stay at McKittrick Hotel, you might need to coordinate separately or use a booking platform. Let me know if you'd like further assistance with hotel arrangements!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 61, 'prompt_tokens': 155, 'total_tokens': 216, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ee1d74bde0', 'id': 'chatcmpl-Bk78fjCgyYrF7TNkIge4X2nTInLTC', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, name='flight_assistant', id='run--24ef1365-60d4-4047-9909-ad2c93d30972-0', usage_metadata={'input_tokens': 155, 'output_tokens': 61, 'total_tokens': 216, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content='Transferring back to supervisor', additional_kwargs={}, response_metadata={'__is_handoff_back': True}, name='flight_assistant', id='30959da0-d6da-41e2-83f4-47a95ee40229', tool_calls=[{'name': 'transfer_back_to_supervisor', 'args': {}, 'id': 'f809d0e0-bb4b-469c-a223-e67617427670', 'type': 'tool_call'}]), ToolMessage(content='Successfully transferred back to supervisor', name='transfer_back_to_supervisor', id='d6ea3bdd-04b5-4fc2-940c-5a2e01e9298d', tool_call_id='f809d0e0-bb4b-469c-a223-e67617427670'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_G8hFci5rIjjleTddUnHy0yDg', 'function': {'arguments': '{}', 'name': 'transfer_to_hotel_assistant'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 249, 'total_tokens': 264, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ee1d74bde0', 'id': 'chatcmpl-Bk78gBAmmepOP9gh70jm97OQ4cOr0', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, name='supervisor', id='run--6bc1aaeb-8ccf-486a-b9a1-6bfe022b71aa-0', tool_calls=[{'name': 'transfer_to_hotel_assistant', 'args': {}, 'id': 'call_G8hFci5rIjjleTddUnHy0yDg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 249, 'output_tokens': 15, 'total_tokens': 264, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='Successfully transferred to hotel_assistant', name='transfer_to_hotel_assistant', id='e41f2c8c-be4d-4b21-b92b-eb263c156f3e', tool_call_id='call_G8hFci5rIjjleTddUnHy0yDg'), AIMessage(content='Your stay at the McKittrick Hotel has been successfully booked. Let me know if you require any additional assistance!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 294, 'total_tokens': 320, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ee1d74bde0', 'id': 'chatcmpl-Bk78iwtyRDFfn3D0FUj6tvUNDPJQE', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, name='hotel_assistant', id='run--a05a3fe9-67ed-4ebb-9de8-55a1310ab42c-0', usage_metadata={'input_tokens': 294, 'output_tokens': 26, 'total_tokens': 320, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content='Transferring back to supervisor', additional_kwargs={}, response_metadata={'__is_handoff_back': True}, name='hotel_assistant', id='3473d686-4e59-4d31-a4c6-5aadbf736771', tool_calls=[{'name': 'transfer_back_to_supervisor', 'args': {}, 'id': 'fca2ca11-926c-493f-8b32-6be25b6e5674', 'type': 'tool_call'}]), ToolMessage(content='Successfully transferred back to supervisor', name='transfer_back_to_supervisor', id='cab3b72d-a5ba-42c0-a5d1-bc2c13f0a3b7', tool_call_id='fca2ca11-926c-493f-8b32-6be25b6e5674'), AIMessage(content=\"Your flight from BOS to JFK and your stay at the McKittrick Hotel have been successfully arranged. Let me know if there's anything else you need!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 363, 'total_tokens': 396, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ee1d74bde0', 'id': 'chatcmpl-Bk78jl905hAlApGn5YNgGlUazPynP', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, name='supervisor', id='run--04a6c430-97a5-43cd-9979-9dd52642c8cc-0', usage_metadata={'input_tokens': 363, 'output_tokens': 33, 'total_tokens': 396, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test code supervisor"
      ],
      "metadata": {
        "id": "JAQu1On80aM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import AzureChatOpenAI\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph_supervisor import create_supervisor\n",
        "\n",
        "# Define tools\n",
        "def book_hotel(hotel_name: str):\n",
        "    \"\"\"Book a hotel\"\"\"\n",
        "    return f\"Successfully booked a stay at {hotel_name}.\"\n",
        "\n",
        "def book_flight(from_airport: str, to_airport: str):\n",
        "    \"\"\"Book a flight\"\"\"\n",
        "    return f\"Successfully booked a flight from {from_airport} to {to_airport}.\"\n",
        "\n",
        "\n",
        "# Azure OpenAI model configuration\n",
        "azure_openai_config = {\n",
        "    \"api_key\": \"1lOkjRo9bsDnbAE2v1qVagkmEj6mT111wak1spzwGQMDsqFoVT1aJQQJ99BDAC5RqLJXJ3w3AAABACOGNvwZ\",\n",
        "    \"api_version\": \"2024-12-01-preview\",\n",
        "    \"azure_endpoint\": \"https://agentic-accelerator-pod-openai-we.openai.azure.com/\",\n",
        "    \"deployment_name\": \"gpt-4o\"\n",
        "}\n",
        "\n",
        "# Create LLM\n",
        "llm = AzureChatOpenAI(\n",
        "    deployment_name=azure_openai_config[\"deployment_name\"],\n",
        "    openai_api_key=azure_openai_config[\"api_key\"],\n",
        "    openai_api_version=azure_openai_config[\"api_version\"],\n",
        "    azure_endpoint=azure_openai_config[\"azure_endpoint\"]\n",
        ")\n",
        "\n",
        "# Create task-specific agents\n",
        "flight_assistant = create_react_agent(\n",
        "    model=llm,\n",
        "    tools=[book_flight],\n",
        "    prompt=\"You are a flight booking assistant\",\n",
        "    name=\"flight_assistant\"\n",
        ")\n",
        "\n",
        "hotel_assistant = create_react_agent(\n",
        "    model=llm,\n",
        "    tools=[book_hotel],\n",
        "    prompt=\"You are a hotel booking assistant\",\n",
        "    name=\"hotel_assistant\"\n",
        ")\n",
        "\n",
        "# Create supervisor agent\n",
        "supervisor = create_supervisor(\n",
        "    agents=[flight_assistant, hotel_assistant],\n",
        "    model=llm,\n",
        "    prompt=\"You manage a hotel booking assistant and a flight booking assistant. Assign work to them.\"\n",
        ").compile()\n",
        "\n",
        "# === Dynamic User Input ===\n",
        "user_input = input(\"Enter your request (e.g., book a flight and a hotel): \")\n",
        "\n",
        "# Pass user input to the supervisor\n",
        "for chunk in supervisor.stream(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": user_input\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "):\n",
        "    print(chunk)\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "id": "UqNOjxIZzaYH",
        "outputId": "8f32da6a-39aa-4854-ddc3-459c7e188675",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your request (e.g., book a flight and a hotel): flight\n",
            "{'supervisor': {'messages': [HumanMessage(content='flight', additional_kwargs={}, response_metadata={}, id='a4ca7acf-62f2-4086-a499-9ed47dd8c9f8'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_1JeD8doLZs74DafIG6G2KVNL', 'function': {'arguments': '{}', 'name': 'transfer_to_flight_assistant'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 85, 'total_tokens': 100, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ee1d74bde0', 'id': 'chatcmpl-Bk7BDmB7VnJ1VzDbevgJb9O7lw2s9', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, name='supervisor', id='run--45493479-567b-40fc-b2f4-2e5668fd62e4-0', tool_calls=[{'name': 'transfer_to_flight_assistant', 'args': {}, 'id': 'call_1JeD8doLZs74DafIG6G2KVNL', 'type': 'tool_call'}], usage_metadata={'input_tokens': 85, 'output_tokens': 15, 'total_tokens': 100, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='Successfully transferred to flight_assistant', name='transfer_to_flight_assistant', id='a2776022-19b7-43cb-9231-0efa3f667a6d', tool_call_id='call_1JeD8doLZs74DafIG6G2KVNL')]}}\n",
            "\n",
            "\n",
            "{'flight_assistant': {'messages': [AIMessage(content='How can I assist you with your flight booking today? Could you let me know your destination and departure location?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 93, 'total_tokens': 117, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ee1d74bde0', 'id': 'chatcmpl-Bk7BDrtBQl2YUG1IrkbwNRyiOS0gG', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, name='flight_assistant', id='run--c02703d1-2416-4ed1-9e88-16dc8cb4e73f-0', usage_metadata={'input_tokens': 93, 'output_tokens': 24, 'total_tokens': 117, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content='Transferring back to supervisor', additional_kwargs={}, response_metadata={'__is_handoff_back': True}, name='flight_assistant', id='3ed41535-5f13-4385-8180-a97bc1af6ffb', tool_calls=[{'name': 'transfer_back_to_supervisor', 'args': {}, 'id': 'bf66445b-b903-467b-aec2-f885ddf7b908', 'type': 'tool_call'}]), ToolMessage(content='Successfully transferred back to supervisor', name='transfer_back_to_supervisor', id='469a1913-4658-4fdd-b7d6-b8552ba80548', tool_call_id='bf66445b-b903-467b-aec2-f885ddf7b908')]}}\n",
            "\n",
            "\n",
            "{'supervisor': {'messages': [HumanMessage(content='flight', additional_kwargs={}, response_metadata={}, id='a4ca7acf-62f2-4086-a499-9ed47dd8c9f8'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_1JeD8doLZs74DafIG6G2KVNL', 'function': {'arguments': '{}', 'name': 'transfer_to_flight_assistant'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 85, 'total_tokens': 100, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ee1d74bde0', 'id': 'chatcmpl-Bk7BDmB7VnJ1VzDbevgJb9O7lw2s9', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, name='supervisor', id='run--45493479-567b-40fc-b2f4-2e5668fd62e4-0', tool_calls=[{'name': 'transfer_to_flight_assistant', 'args': {}, 'id': 'call_1JeD8doLZs74DafIG6G2KVNL', 'type': 'tool_call'}], usage_metadata={'input_tokens': 85, 'output_tokens': 15, 'total_tokens': 100, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='Successfully transferred to flight_assistant', name='transfer_to_flight_assistant', id='a2776022-19b7-43cb-9231-0efa3f667a6d', tool_call_id='call_1JeD8doLZs74DafIG6G2KVNL'), AIMessage(content='How can I assist you with your flight booking today? Could you let me know your destination and departure location?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 93, 'total_tokens': 117, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ee1d74bde0', 'id': 'chatcmpl-Bk7BDrtBQl2YUG1IrkbwNRyiOS0gG', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, name='flight_assistant', id='run--c02703d1-2416-4ed1-9e88-16dc8cb4e73f-0', usage_metadata={'input_tokens': 93, 'output_tokens': 24, 'total_tokens': 117, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content='Transferring back to supervisor', additional_kwargs={}, response_metadata={'__is_handoff_back': True}, name='flight_assistant', id='3ed41535-5f13-4385-8180-a97bc1af6ffb', tool_calls=[{'name': 'transfer_back_to_supervisor', 'args': {}, 'id': 'bf66445b-b903-467b-aec2-f885ddf7b908', 'type': 'tool_call'}]), ToolMessage(content='Successfully transferred back to supervisor', name='transfer_back_to_supervisor', id='469a1913-4658-4fdd-b7d6-b8552ba80548', tool_call_id='bf66445b-b903-467b-aec2-f885ddf7b908'), AIMessage(content=\"Welcome back! Let me know if you'd like assistance with anything else. Are you seeking flight or hotel help now?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 197, 'total_tokens': 222, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ee1d74bde0', 'id': 'chatcmpl-Bk7BEimf1awXzQtj9YzhuIQvOvXI4', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, name='supervisor', id='run--0752c0a3-6203-4bb3-8159-507e5d8a46dd-0', usage_metadata={'input_tokens': 197, 'output_tokens': 25, 'total_tokens': 222, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}